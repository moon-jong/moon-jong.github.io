---
title: AI math 5 통계학 맛보기
use_math: true
tags:
- math
- statistics
---

# Intro
통계 관련한 부분에 대한 기초를 다루었다. 
오늘은 특히나 헷갈리는 개념과 용어가 자주 등장하여 애를먹었다.

표본분포, 표집분포, 가능도와 확률 등 굉장히 헷갈리기 쉬운 개념들이 등장하여 이를 정리하는데도 애를먹었다.

~~자 그럼 드랍더 빗...~~

# 통계

## 모수
모수 역시 헷갈리는 개념중 하나였다. 때문에 피어세션에서 모수란 무엇인가에 대한 토론이 이어졌다.
한문장으로 정리하면

**모수 : 모집단을 설명해주는 수**  이다.

아니 이게 무슨말인가. 못해도 수천 수만의 데이터가 있을터인데 어떻게 몇가지 수로만 데이터를 설명할 수 있다는 것일까?

하지만 가능하다

예를들어 정규분포의 경우 평균과 표준편차만 있다면 그래프를 그릴 수 있다.
따라서 정규분포의 경우 평균과 표준편차가 모수라 할 수 있다.

하지만 모수가 단지 평균과 표준편차만 존재하는것은 아니다.
데이터에 따라 수많은 모수가 존재할 수 있고 상당히 여러 값을 가질 수 있다.

하지만 궁극적으로 통계는 몇개인지, 어떤 모수가 모집단을 대표하는 모수인지 모를 때에도 모집단을 대표하는 수 **모수**를 *추정*하는 학문이라 할 수 있다.

## 표본분포와 표집분포
표본분포(sample distribution)는 우리가 꽤나 익히 들어온 개념이다
우리가 모집단에서 한 그룹의 샘플링을 하였다고 가정하면 그 샘플 공간 내에서 데이터들의 분포를 이야기하는게 표본 분포다

하지만 표집분포(sampling distribution)는 조금 다르다. 
하나의 모집단에서 *독립적으로* 여러번 샘플링을 하였을 때 통계량의 확률분포를 표집분포라 한다.

0부터 100까지의 정수 있는 벡터 공간에서 10개씩 100번 샘플링 하였다고 해보자
그리고 각 샘플마다 평균을 취하면 하나의 행벡터가 나오는데  이 행벡터의 확률변수 분포가 표집분포가 된다.

아래 그림을 보자
![]({{ 'assets/img/images/sampling.png' | relative_url }})

위의 그림은 언급하였던 과정을 왼쪽부터 40번 반복하였을때, 1000번 하였을때, 1만번 하였을때의 분포를 나타내었다.

샘플링을 많이하면 할수록 정규분포를 따르는것을 확인할 수 있다.
표집분포는 위의 세 그림이 나타내는 분포를 따르며 

샘플링을 많이하면 할수록 정규분포에 가까워진다는 이론은 중심극한정리이다.

## 가능도와 MLE
결국 통계는 모수를 추정하는 과정이라고 짧은 지식으로 이야기하였다.

머신러닝과 딥러닝에서 모수추정에 많이 사용되는 개념이 최대 가능도 추정이다(MLE)

하지만 가능도를 들어가기에 앞서 확률과 가능도의 차이부터 알아보고자한다.

아래는 정규분포를 따르는 그래프이다.

![]({{ 'assets/img/images/normal.png' | relative_url }})

이 그래프를 연속확률변수 공간이라고 생각하면 이 분포에서 한 점을 추정하는것은 $\frac{1}{\infty}$이므로 불가능하다
우리는 보통 확률을 구한다고한다면 정규분포 범위 내의 구간을 통하여 $\frac{특정구간}{전체면적}$으로 구할것이다. 이를 확률이라한다.

하지만 가능도는 위의 그래프에서 특정 점에서의 y값이다. 즉 구간중 가장 사건이 일어날 가능성이 높은 점이다. 

머신러닝과 딥러닝에선 이러한 최대 가능도 추정을 이용하여 모수를 추정하는 방식을 채택하고있다.


# Outro
아직 확률 관련하여 수식, 예제를 정리하지 못하였다.
주말동안 다시 정리해야지...
